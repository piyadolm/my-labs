# Understand responsible AI

AI software development is guided by a set of six principles, designed to ensure that AI applications provide amazing solutions to difficult problems without any unintended negative consequences.

## 1. Fairness

**AI systems should treat all people fairly**, no bias based on anything (e.g. gender, ethnicity) that might result in an unfair avantage or disadvantage to specific groups of users.

## 2. Reliability and safety

For example, consider an AI-based software system for an autonomous vehicle; or a machine learning model that diagnoses patient symptoms and recommends prescriptions. Unreliability in these kinds of system can result in substantial risk to human life.

AI-based software application development must be subjected to rigorous testing and deployment management processes to ensure that they work as expected before release.

## 3. Privacy and security

The machine learning models on which AI systems are based rely on **large volumes of data**, which may **contain personal details** that must be **kept private**.

## 4. Inclusiveness

AI systems should **empower everyone** and **engage people**. AI should bring benefits to all parts of society, regardless of physical ability, gender, sexual orientation, ethnicity, or other factors.

## 5. Transparency

AI systems should be **understandable**. Users should be made **fully aware of the purpose of the system**, how it works, and what limitations may be expected.

## 6. Accountability

**People** should be **accountable for AI systems**. Designers and developers of AI-based solution should work within a framework of governance and organizational principles that **ensure the solution meets ethical and legal standards** that are clearly defined.
